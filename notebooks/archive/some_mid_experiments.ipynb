{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Dense, Activation, BatchNormalization\n",
    "from keras.layers import activations, initializers, regularizers, constraints, Lambda\n",
    "from keras.engine import InputSpec\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class AMSoftmax(Layer):\n",
    "    def __init__(self, units, s, m,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 kernel_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(AMSoftmax, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.input_spec = InputSpec(min_ndim=2)\n",
    "        self.supports_masking = True\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 2\n",
    "        input_dim = input_shape[-1]\n",
    "\n",
    "        self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        self.bias = None\n",
    "\n",
    "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n",
    "        self.built = True\n",
    "\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        inputs = tf.nn.l2_normalize(inputs, dim=-1)\n",
    "        self.kernel = tf.nn.l2_normalize(self.kernel, dim=(0, 1))   # W归一化\n",
    "\n",
    "        dis_cosin = K.dot(inputs, self.kernel)\n",
    "        psi = dis_cosin - self.m\n",
    "\n",
    "        e_costheta = K.exp(self.s * dis_cosin)\n",
    "        e_psi = K.exp(self.s * psi)\n",
    "        sum_x = K.sum(e_costheta, axis=-1, keepdims=True)\n",
    "\n",
    "        temp = e_psi - e_costheta\n",
    "        temp = temp + sum_x\n",
    "\n",
    "        output = e_psi / temp\n",
    "        return output\n",
    "\n",
    "\n",
    "def amsoftmax_loss(y_true, y_pred):\n",
    "    d1 = K.sum(y_true * y_pred, axis=-1)\n",
    "    d1 = K.log(K.clip(d1, K.epsilon(), None))\n",
    "    loss = -K.mean(d1, axis=-1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-545bf718ca62>:21: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "(55000, 28, 28, 1) (10000, 28, 28, 1) (55000, 10) (10000, 10)\n",
      "(55000, 784) (10000, 784) (55000, 10) (10000, 10)\n",
      "55000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:From <ipython-input-3-6a95c5171ee8>:46: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "am_softmax_1 (AMSoftmax)     (None, 500)               5000      \n",
      "=================================================================\n",
      "Total params: 648,000\n",
      "Trainable params: 648,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 2s 44us/step - loss: 3.6102 - acc: 0.8740 - val_loss: 2.8146 - val_acc: 0.9406\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 3.0701 - acc: 0.9407 - val_loss: 2.6992 - val_acc: 0.9493\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 2.9924 - acc: 0.9519 - val_loss: 2.6345 - val_acc: 0.9619\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 2.9773 - acc: 0.9551 - val_loss: 2.6210 - val_acc: 0.9646\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 2.9467 - acc: 0.9620 - val_loss: 2.6159 - val_acc: 0.9669\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 2.9359 - acc: 0.9644 - val_loss: 2.6136 - val_acc: 0.9653\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 2.9233 - acc: 0.9680 - val_loss: 2.5906 - val_acc: 0.9713\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 2.9081 - acc: 0.9713 - val_loss: 2.5981 - val_acc: 0.9698\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 2.9058 - acc: 0.9723 - val_loss: 2.6004 - val_acc: 0.9686\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 2s 40us/step - loss: 2.8998 - acc: 0.9733 - val_loss: 2.5860 - val_acc: 0.9726\n",
      "Test score: 2.58602007713\n",
      "Test accuracy: 0.9726\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense,Input,Conv2D,MaxPooling2D,Dropout,BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adam\n",
    "import os\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "batch_size = 200\n",
    "nb_classes = 10\n",
    "nb_epoch = 2\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "X_train, Y_train = mnist.train.images,mnist.train.labels\n",
    "X_test, Y_test = mnist.test.images, mnist.test.labels\n",
    "X_train = X_train.reshape(-1, 28, 28,1).astype('float32')\n",
    "X_test = X_test.reshape(-1,28, 28,1).astype('float32')\n",
    "\n",
    "#打印训练数据和测试数据的维度\n",
    "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)\n",
    "\n",
    "#修改维度\n",
    "X_train = X_train.reshape(55000,784)\n",
    "X_test = X_test.reshape(10000,784)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "# 将X_train, X_test的数据格式转为float32存储\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# 归一化\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# 打印出训练集和测试集的信息\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "x_input = Input(shape=(784,))\n",
    "y = Dense(500, activation='relu')(x_input)\n",
    "y = Dropout(0.2)(y)\n",
    "y = Dense(500, activation='relu')(y)\n",
    "y = Dropout(0.2)(y)\n",
    "\n",
    "output = AMSoftmax(10, 10, 0.35)(y)\n",
    "#output = Dense(10, activation='softmax')(y)\n",
    "model = Model(inputs=x_input, outputs=output)\n",
    "model.summary()\n",
    "\n",
    "adam = Adam()\n",
    "model.compile(loss=amsoftmax_loss,\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import *\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Convolution2D(32, 3, padding='same',\n",
    "                               input_shape=(32, 32, 3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Convolution2D(32, 3))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Convolution2D(64, 3, padding='same'))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Convolution2D(64, 3))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(AMSoftmax(10, 10, 0.35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "train_images = train_images.reshape((50000, 32, 32, 3))\n",
    "test_images = test_images.reshape((10000, 32, 32, 3))\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "# train_images, test_images = train_images - 0.5, test_images - 0.5\n",
    "# train_images, test_images = train_images * 2, test_images * 2\n",
    "\n",
    "# To one-hot\n",
    "train_labels = utils.to_categorical(train_labels, 10)\n",
    "test_labels = utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 4.9320 - acc: 0.4068 - val_loss: 4.3271 - val_acc: 0.5199\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 4.5617 - acc: 0.5447 - val_loss: 4.0762 - val_acc: 0.5889\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 4.4278 - acc: 0.5967 - val_loss: 3.9169 - val_acc: 0.6129\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 4.3412 - acc: 0.6339 - val_loss: 3.8386 - val_acc: 0.6544\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 4.2831 - acc: 0.6588 - val_loss: 3.7594 - val_acc: 0.6649\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 4.2369 - acc: 0.6763 - val_loss: 3.6902 - val_acc: 0.6976\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 4.2024 - acc: 0.6941 - val_loss: 3.6757 - val_acc: 0.6943\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 4.1697 - acc: 0.7087 - val_loss: 3.5988 - val_acc: 0.7083\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 4.1430 - acc: 0.7172 - val_loss: 3.5633 - val_acc: 0.7287\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 4.1200 - acc: 0.7285 - val_loss: 3.5563 - val_acc: 0.7304\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=amsoftmax_loss,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history1 = model.fit(train_images, train_labels, epochs=10,\n",
    "                     validation_data=(test_images, test_labels));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/Joker316701882/Additive-Margin-Softmax/issues/9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
